# TFIDF

2022-04-21
这个概念老早就听过，之前也知道它的含义，但是很久没有接触，已经淡忘

Term Frequency - Inverse Document Frequency

TF词频，另一个是逆文档频率

- TF = 某个词在文章中出现次数 / 文章的总词数
- IDF 逆文档频率。 这时需要一个语料库，用来模拟语言的使用环境。 IDF = log(语料库的文档总数 / 包含该词的文档数 + 1)
这里面，一个词越常见，分母就越大，逆文档频率就越小接近0。 分母加1是为了避免分母为0的情况（所有文档都不包含该词）
- TF-IDF = TF * IDF
-

含义很简单易懂，巧妙简洁。

这个背后的假设非常质朴，一篇文章里面某个关键词出现次数越多则越重要，显然这个假设有点过于简化。 如果有一些垃圾文章，全篇只包含
一个关键词，则这个关键词一旦被搜索，肯定会排在最前
