# Regularization

正则化的概念，还是理解的不够深入，需要好好整理一下


先讨论几个问题：
1）实现参数的稀疏有什么好处吗？

一个好处是可以简化模型，避免过拟合。因为一个模型中真正重要的参数可能并不多，如果考虑所有的参数起作用，那么可以对训练数据可以预测的很好，但是对测试数据就只能呵呵了。另一个好处是参数变少可以使整个模型获得更好的可解释性。

2）参数值越小代表模型越简单吗？

是的。为什么参数越小，说明模型越简单呢，这是因为越复杂的模型，越是会尝试对所有的样本进行拟合，甚至包括一些异常样本点，这就容易造成在较小的区间里预测值产生较大的波动，这种较大的波动也反映了在这个区间里的导数很大，而只有较大的参数值才能产生较大的导数。因此复杂的模型，其参数值会比较大。


## L1

L1 范数，在0值处不可导，0处是极值点，很容易优化到0点。 
另一个角度来看，L1的等值曲线是菱形，而参数的等值曲线是弧形，两边相交处很容易发生在坐标0点处，因此导致了特征的稀疏

## L2
L2 的等值曲线是光滑的，与参数的等值曲线相切的点可能发生在各个地方，因此优化导致特征的平坐标0点处，因此导致了特征的稀疏

## LASSO, Ridge
L1范数是指向量中各个元素绝对值之和，也称为Lasso regularization；L2范数是指向量中各个元素平方之和, 也称为Ridge regularization

