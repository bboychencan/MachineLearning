# Ridge Regression

岭回归其实就是线性回归的一个变种，线性回归采用平方损失函数，采用最小二乘法求解。

在线性回归模型中，其参数估计公式里X^T X如果不可逆就无法计算。且如果他越趋近于0，会使得回归系数趋向于无穷大，此时得到的回归系数是无意义的。解决这类问题可以使用岭回归和LASSO回归，主要针对自变量之间存在多重共线性或者自变量个数多于样本量的情况。

在损失函数后面加上L1正则化就成为了Lasso回归（least absolute shrinkage and selection operator）
或者L2正则化就成为了岭回归

1. L1正则化最大的特点是能稀疏矩阵，进行庞大特征数量下的特征选择
2. L2正则化能够有效的防止模型过拟合，解决非满秩下求逆困难的问题

岭回归的代价函数仍然是一个凸函数，因此可以利用梯度等于0的方式求得全局最优解（正规方程）：

𝜃=(𝑋𝑇𝑋+𝜆𝐼)−1(𝑋𝑇𝑦)

上述正规方程与一般线性回归的正规方程相比，多了一项𝜆𝐼，其中𝐼表示单位矩阵。假如𝑋𝑇𝑋是一个奇异矩阵（不满秩），添加这一项后可以保证该项可逆。由于单位矩阵的形状是对角线上为1其他地方都为0，看起来像一条山岭，因此而得名。