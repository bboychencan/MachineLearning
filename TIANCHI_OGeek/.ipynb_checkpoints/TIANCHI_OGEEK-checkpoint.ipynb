{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import jieba, os, Levenshtein, time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "from utility import read_file, lcseque_lens, lcsubstr_lens, find_longest_prefix, printlog\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from xpinyin import Pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run base_feature\n"
     ]
    }
   ],
   "source": [
    "print('run base_feature')\n",
    "# 配置信息\n",
    "is_print_output = True\n",
    "all_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 读入数据\n",
    "train_data = read_file('./data/oppo_round1_train_20180929.txt')\n",
    "val_data = read_file('./data/oppo_round1_vali_20180929.txt')\n",
    "test_data = read_file('./data/oppo_round1_test_A_20180929.txt', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 0m 52s\n"
     ]
    }
   ],
   "source": [
    "# 拼接数据一起做特征\n",
    "not_zip_all_data = pd.concat((train_data, val_data, test_data), axis=0, ignore_index=True, sort=False)\n",
    "time_elapsed = time.time() - since\n",
    "print('completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in 0m 1s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "#Fix empty query_prediction\n",
    "not_zip_all_data.loc[not_zip_all_data['query_prediction'] == '', 'query_prediction'] = '{}'\n",
    "#Change label to int\n",
    "not_zip_all_data['label'] = not_zip_all_data['label'].astype('int')\n",
    "#Save to-drop columns\n",
    "drop_feature = []\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in 0m 5s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "not_zip_all_data['diction_label'] = encoder.fit_transform(not_zip_all_data.query_prediction)\n",
    "\n",
    "# Remove duplicate, calculate staticstics features\n",
    "all_data = not_zip_all_data.drop('label', axis = 1).drop_duplicates().reset_index(drop = True)\n",
    "drop_feature.append('diction_label')\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in 0m 14s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "def str_to_dict(dict_str):\n",
    "    my_dict = eval(dict_str)\n",
    "    keys, values = my_dict.keys(), my_dict.values()\n",
    "    my_dict = dict(zip(keys, list(map(lambda x: float(x), values))))\n",
    "    return my_dict\n",
    "\n",
    "all_data['query_prediction'] = all_data.query_prediction.apply(lambda x: str_to_dict(x))\n",
    "all_data['max_query_prediction_keys'] = all_data.query_prediction.apply(lambda x: '' if x == {} else max(x, key=x.get))\n",
    "all_data['query_prediction_keys'] = all_data.query_prediction.apply(lambda x: list(x.keys()))\n",
    "all_data['query_prediciton_values'] = all_data.query_prediction.apply(lambda x: list(x.values()))\n",
    "\n",
    "drop_feature.extend(['query_prediction', 'query_prediction_keys', 'query_prediction_values', 'max_query_prediction_keys'])\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in 0m 39s\n"
     ]
    }
   ],
   "source": [
    "# 分词\n",
    "since = time.time()\n",
    "all_data['prefix_jieba'] = all_data.prefix.apply(lambda x: \" \".join(jieba.cut(x, cut_all = False)))\n",
    "all_data['prefix_jieba'] = all_data.prefix_jieba.apply(lambda x: \" \".join(x.split()))\n",
    "all_data['title_jieba'] = all_data.title.apply(lambda x: \" \".join(jieba.cut(x, cut_all = False)))\n",
    "all_data['title_jieba'] = all_data.title_jieba.apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "all_data['query_jieba'] = all_data.max_query_prediction_keys.apply(lambda x: \" \".join(jieba.cut(x, cut_all = False)))\n",
    "all_data['query_jieba'] = all_data.query_jieba.apply(lambda x: \" \".join(x.split()))\n",
    "drop_feature.extend(['prefix_jieba', 'title_jieba', 'query_jieba'])\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 转换成拼音\n",
    "p = Pinyin()\n",
    "all_data['prefix_pinyin'] = all_data.prefix.apply(lambda x: p.get_pinyin(x, ' '))\n",
    "\n",
    "drop_feature.append('prefix_pinyin')\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>query_prediction</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>diction_label</th>\n",
       "      <th>max_query_prediction_keys</th>\n",
       "      <th>query_prediction_keys</th>\n",
       "      <th>query_prediciton_values</th>\n",
       "      <th>prefix_jieba</th>\n",
       "      <th>title_jieba</th>\n",
       "      <th>query_jieba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小品</td>\n",
       "      <td>{'小品大全宋小宝': 0.009, '小品相亲': 0.012, '小品剧本': 0.02...</td>\n",
       "      <td>小品</td>\n",
       "      <td>阅读</td>\n",
       "      <td>56723</td>\n",
       "      <td>小品大全</td>\n",
       "      <td>[小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...</td>\n",
       "      <td>[0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...</td>\n",
       "      <td>小品</td>\n",
       "      <td>小品</td>\n",
       "      <td>小品 大全</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13688cc赛马会': 0.059, '13685367892': 0.124, '1...</td>\n",
       "      <td>HCG大于1368%2C正常吗</td>\n",
       "      <td>健康</td>\n",
       "      <td>236</td>\n",
       "      <td>13685367892</td>\n",
       "      <td>[13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...</td>\n",
       "      <td>[0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...</td>\n",
       "      <td>1368</td>\n",
       "      <td>HCG 大于 1368% 2C 正常 吗</td>\n",
       "      <td>13685367892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13688cc赛马会': 0.059, '13685367892': 0.124, '1...</td>\n",
       "      <td>1368年</td>\n",
       "      <td>百科</td>\n",
       "      <td>236</td>\n",
       "      <td>13685367892</td>\n",
       "      <td>[13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...</td>\n",
       "      <td>[0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...</td>\n",
       "      <td>1368</td>\n",
       "      <td>1368 年</td>\n",
       "      <td>13685367892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>银耳</td>\n",
       "      <td>{'银耳汤的功效': 0.012, '银耳为什么不能天天吃': 0.009, '银耳莲子羹'...</td>\n",
       "      <td>银耳红枣汤的做法</td>\n",
       "      <td>菜谱</td>\n",
       "      <td>148689</td>\n",
       "      <td>银耳红枣汤</td>\n",
       "      <td>[银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...</td>\n",
       "      <td>[0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...</td>\n",
       "      <td>银耳</td>\n",
       "      <td>银耳 红枣汤 的 做法</td>\n",
       "      <td>银耳 红枣汤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>月经量少</td>\n",
       "      <td>{'月经量少喝红糖水好吗': 0.01, '月经量少该怎么调理': 0.016, '月经量少...</td>\n",
       "      <td>月经量少怎么调理</td>\n",
       "      <td>百科</td>\n",
       "      <td>82044</td>\n",
       "      <td>月经量少是什么原因</td>\n",
       "      <td>[月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...</td>\n",
       "      <td>[0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...</td>\n",
       "      <td>月经 量少</td>\n",
       "      <td>月经 量少 怎么 调理</td>\n",
       "      <td>月经 量少 是 什么 原因</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345375</th>\n",
       "      <td>银行承兑</td>\n",
       "      <td>{'银行承兑贴现计算器': 0.012, '银行承兑汇票期限': 0.044, '银行承兑汇...</td>\n",
       "      <td>银行承兑汇票到期如何变现？</td>\n",
       "      <td>知道</td>\n",
       "      <td>148773</td>\n",
       "      <td>银行承兑汇票</td>\n",
       "      <td>[银行承兑贴现计算器, 银行承兑汇票期限, 银行承兑汇票贴现, 银行承兑到期怎么兑现, 银行...</td>\n",
       "      <td>[0.012, 0.044, 0.087, 0.012, 0.495, 0.041, 0.0...</td>\n",
       "      <td>银行 承兑</td>\n",
       "      <td>银行 承兑汇票 到期 如何 变现 ？</td>\n",
       "      <td>银行 承兑汇票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345376</th>\n",
       "      <td>起名大全</td>\n",
       "      <td>{'起名大全2016最新版的': 0.001, '起名大全女孩': 0.023, '起名大全...</td>\n",
       "      <td>宝宝吉祥起名大全</td>\n",
       "      <td>百科</td>\n",
       "      <td>140479</td>\n",
       "      <td>起名大全免费</td>\n",
       "      <td>[起名大全2016最新版的, 起名大全女孩, 起名大全女孩免费, 起名大全免费, 起名大全软...</td>\n",
       "      <td>[0.001, 0.023, 0.001, 0.054, 0.001, 0.023, 0.0...</td>\n",
       "      <td>起名 大全</td>\n",
       "      <td>宝宝 吉祥 起名 大全</td>\n",
       "      <td>起名 大 全免费</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345377</th>\n",
       "      <td>护眼</td>\n",
       "      <td>{'护眼壁纸手机高清绿色': 0.033, '护眼图片': 0.052, '护眼软件': 0...</td>\n",
       "      <td>绿色护眼壁纸</td>\n",
       "      <td>百科</td>\n",
       "      <td>73805</td>\n",
       "      <td>护眼壁纸</td>\n",
       "      <td>[护眼壁纸手机高清绿色, 护眼图片, 护眼软件, 护眼仪有用吗, 护眼宝, 护眼灯什么牌子好...</td>\n",
       "      <td>[0.033, 0.052, 0.022, 0.013, 0.065, 0.014, 0.0...</td>\n",
       "      <td>护眼</td>\n",
       "      <td>绿色 护眼 壁纸</td>\n",
       "      <td>护眼 壁纸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345378</th>\n",
       "      <td>亚美</td>\n",
       "      <td>{'亚美科技': 0.134, '亚美车智汇': 0.06, '亚美车智汇是传销吗': 0....</td>\n",
       "      <td>亚美</td>\n",
       "      <td>百科</td>\n",
       "      <td>17724</td>\n",
       "      <td>亚美科技</td>\n",
       "      <td>[亚美科技, 亚美车智汇, 亚美车智汇是传销吗, 亚美娱乐, 亚美车智汇国家支持吗, 亚美尼...</td>\n",
       "      <td>[0.134, 0.06, 0.037, 0.023, 0.028, 0.074, 0.02...</td>\n",
       "      <td>亚美</td>\n",
       "      <td>亚美</td>\n",
       "      <td>亚美 科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345379</th>\n",
       "      <td>淋巴细胞</td>\n",
       "      <td>{'淋巴细胞比率偏高': 0.025, '淋巴细胞比率高': 0.018, '淋巴细胞低':...</td>\n",
       "      <td>淋巴细胞高</td>\n",
       "      <td>健康</td>\n",
       "      <td>96034</td>\n",
       "      <td>淋巴细胞百分比偏高</td>\n",
       "      <td>[淋巴细胞比率偏高, 淋巴细胞比率高, 淋巴细胞低, 淋巴细胞百分比, 淋巴细胞百分比偏高,...</td>\n",
       "      <td>[0.025, 0.018, 0.032, 0.08, 0.239, 0.018, 0.08...</td>\n",
       "      <td>淋巴细胞</td>\n",
       "      <td>淋巴细胞 高</td>\n",
       "      <td>淋巴细胞 百分比 偏高</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345380 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prefix                                   query_prediction  \\\n",
       "0          小品  {'小品大全宋小宝': 0.009, '小品相亲': 0.012, '小品剧本': 0.02...   \n",
       "1        1368  {'13688cc赛马会': 0.059, '13685367892': 0.124, '1...   \n",
       "2        1368  {'13688cc赛马会': 0.059, '13685367892': 0.124, '1...   \n",
       "3          银耳  {'银耳汤的功效': 0.012, '银耳为什么不能天天吃': 0.009, '银耳莲子羹'...   \n",
       "4        月经量少  {'月经量少喝红糖水好吗': 0.01, '月经量少该怎么调理': 0.016, '月经量少...   \n",
       "...       ...                                                ...   \n",
       "345375   银行承兑  {'银行承兑贴现计算器': 0.012, '银行承兑汇票期限': 0.044, '银行承兑汇...   \n",
       "345376   起名大全  {'起名大全2016最新版的': 0.001, '起名大全女孩': 0.023, '起名大全...   \n",
       "345377     护眼  {'护眼壁纸手机高清绿色': 0.033, '护眼图片': 0.052, '护眼软件': 0...   \n",
       "345378     亚美  {'亚美科技': 0.134, '亚美车智汇': 0.06, '亚美车智汇是传销吗': 0....   \n",
       "345379   淋巴细胞  {'淋巴细胞比率偏高': 0.025, '淋巴细胞比率高': 0.018, '淋巴细胞低':...   \n",
       "\n",
       "                  title tag  diction_label max_query_prediction_keys  \\\n",
       "0                    小品  阅读          56723                      小品大全   \n",
       "1       HCG大于1368%2C正常吗  健康            236               13685367892   \n",
       "2                 1368年  百科            236               13685367892   \n",
       "3              银耳红枣汤的做法  菜谱         148689                     银耳红枣汤   \n",
       "4              月经量少怎么调理  百科          82044                 月经量少是什么原因   \n",
       "...                 ...  ..            ...                       ...   \n",
       "345375    银行承兑汇票到期如何变现？  知道         148773                    银行承兑汇票   \n",
       "345376         宝宝吉祥起名大全  百科         140479                    起名大全免费   \n",
       "345377           绿色护眼壁纸  百科          73805                      护眼壁纸   \n",
       "345378               亚美  百科          17724                      亚美科技   \n",
       "345379            淋巴细胞高  健康          96034                 淋巴细胞百分比偏高   \n",
       "\n",
       "                                    query_prediction_keys  \\\n",
       "0       [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
       "1       [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
       "2       [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
       "3       [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
       "4       [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
       "...                                                   ...   \n",
       "345375  [银行承兑贴现计算器, 银行承兑汇票期限, 银行承兑汇票贴现, 银行承兑到期怎么兑现, 银行...   \n",
       "345376  [起名大全2016最新版的, 起名大全女孩, 起名大全女孩免费, 起名大全免费, 起名大全软...   \n",
       "345377  [护眼壁纸手机高清绿色, 护眼图片, 护眼软件, 护眼仪有用吗, 护眼宝, 护眼灯什么牌子好...   \n",
       "345378  [亚美科技, 亚美车智汇, 亚美车智汇是传销吗, 亚美娱乐, 亚美车智汇国家支持吗, 亚美尼...   \n",
       "345379  [淋巴细胞比率偏高, 淋巴细胞比率高, 淋巴细胞低, 淋巴细胞百分比, 淋巴细胞百分比偏高,...   \n",
       "\n",
       "                                  query_prediciton_values prefix_jieba  \\\n",
       "0       [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...           小品   \n",
       "1       [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...         1368   \n",
       "2       [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...         1368   \n",
       "3       [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...           银耳   \n",
       "4       [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...        月经 量少   \n",
       "...                                                   ...          ...   \n",
       "345375  [0.012, 0.044, 0.087, 0.012, 0.495, 0.041, 0.0...        银行 承兑   \n",
       "345376  [0.001, 0.023, 0.001, 0.054, 0.001, 0.023, 0.0...        起名 大全   \n",
       "345377  [0.033, 0.052, 0.022, 0.013, 0.065, 0.014, 0.0...           护眼   \n",
       "345378  [0.134, 0.06, 0.037, 0.023, 0.028, 0.074, 0.02...           亚美   \n",
       "345379  [0.025, 0.018, 0.032, 0.08, 0.239, 0.018, 0.08...         淋巴细胞   \n",
       "\n",
       "                 title_jieba    query_jieba  \n",
       "0                         小品          小品 大全  \n",
       "1       HCG 大于 1368% 2C 正常 吗    13685367892  \n",
       "2                     1368 年    13685367892  \n",
       "3                银耳 红枣汤 的 做法         银耳 红枣汤  \n",
       "4                月经 量少 怎么 调理  月经 量少 是 什么 原因  \n",
       "...                      ...            ...  \n",
       "345375    银行 承兑汇票 到期 如何 变现 ？        银行 承兑汇票  \n",
       "345376           宝宝 吉祥 起名 大全       起名 大 全免费  \n",
       "345377              绿色 护眼 壁纸          护眼 壁纸  \n",
       "345378                    亚美          亚美 科技  \n",
       "345379                淋巴细胞 高    淋巴细胞 百分比 偏高  \n",
       "\n",
       "[345380 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since = time.time()\n",
    "# 去掉prefix、title中的空格，转换大小写\n",
    "all_data['prefix_fix'] = all_data.prefix.apply(lambda x: x.replace(' ', '').lower())\n",
    "all_data['title_fix'] = all_data.title.apply(lambda x: x.replace(' ', '').lower())\n",
    "all_data['query_fix'] = all_data.max_query_prediction_keys.apply(lambda x: x.replace(' ', '').lower())\n",
    "all_data['query_prediction_keys_fix'] = all_data.query_prediction_keys.apply(lambda x: list(map(lambda item: item.replace(' ', '').lower(), x)))\n",
    "\n",
    "drop_feature.extend(['prefix_fix', 'title_fix', 'query_fix', 'query_prediction_keys_fix'])\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# ----- length 特征 -----\n",
    "list_length_feature = ['prefix', 'title', 'max_query_prediction_keys', 'query_prediction_values']\n",
    "\n",
    "for feature in list_length_feature:\n",
    "    printlog('计算' + feature + '长度', is_print_output)\n",
    "    all_data[feature + '_length'] = all_data[feature].apply(lambda x: len(x))\n",
    "for feature in ['prefix_jieba', 'title_jieba', 'query_jieba']:\n",
    "    all_data[feature + '_length'] = all_data[feature].apply(lambda x: len(x.split()))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# ----- nunique 特征 -----\n",
    "list_nunique_feature = ['prefix', 'title', 'tag', 'max_query_prediction_keys', 'prefix_pinyin']\n",
    "\n",
    "all_data['prefix_nunique_title'] = all_data.groupby('prefix').title.transform('nunique')\n",
    "all_data['prefix_nunique_tag'] = all_data.groupby('prefix').tag.transform('nunique')\n",
    "\n",
    "all_data['title_nunique_prefix'] = all_data.groupby('title').prefix.transform('nunique')\n",
    "all_data['title_nunique_tag'] = all_data.groupby('title').tag.transform('nunique')\n",
    "all_data['title_nunique_query'] = all_data.groupby('title').max_query_prediction_keys.transform('nunique')\n",
    "all_data['title_nunique_prefix_pinyin'] = all_data.groupby('title').prefix_pinyin.transform('nunique')\n",
    "\n",
    "all_data['tag_nunique_prefix'] = all_data.groupby('tag').prefix.transform('nunique')\n",
    "all_data['tag_nunique_title'] = all_data.groupby('tag').title.transform('nunique')\n",
    "all_data['tag_nunique_max_query'] = all_data.groupby('tag').max_query_prediction_keys.transform('nunique')\n",
    "\n",
    "all_data['query_nunique_prefix'] = all_data.groupby('max_query_prediction_keys').prefix.transform('nunique')\n",
    "all_data['query_nunique_title'] = all_data.groupby('max_query_prediction_keys').title.transform('nunique')\n",
    "all_data['query_nunique_tag'] = all_data.groupby('max_query_prediction_keys').tag.transform('nunique')\n",
    "all_data['query_nunique_prefix_pinyin'] = all_data.groupby('max_query_prediction_keys').prefix_pinyin.transform('nunique')\n",
    "\n",
    "all_data['prefix_pinyin_nunique_prefix'] = all_data.groupby('prefix_pinyin').prefix.transform('nunique')\n",
    "all_data['prefix_pinyin_nunique_title'] = all_data.groupby('prefix_pinyin').title.transform('nunique')\n",
    "all_data['prefix_pinyin_nunique_tag'] = all_data.groupby('prefix_pinyin').tag.transform('nunique')\n",
    "all_data['prefix_pinyin_nunique_query'] = all_data.groupby('prefix_pinyin').max_query_prediction_keys.transform('nunique')\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# is in feature\n",
    "all_data['prefix_isin_title'] = all_data.apply(lambda row:1 if row['prefix_fix'] in row['title_fix'] else 0, axis = 1)\n",
    "all_data['tag_isin_title'] = all_data.apply(lambda row:1 if row['tag'] in row['title_fix'] else 0, axis = 1)\n",
    "all_data['query_isin_title'] = all_data.apply(lambda row:1 if row['query_fix'] in row['title_fix'] else 0, axis = 1)\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_func = [Levenshtein.ratio, Levenshtein.distance, lcsubstr_lens, lcseque_lens]\n",
    "statistics_func = [max, min, np.mean, np.std]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 计算prefix/title与query_prediction_keys相似度的list\n",
    "list_with_query_prediction_keys_similarity = ['prefix_fix', 'title_fix']\n",
    "for feature in list_with_query_prediction_keys_similarity:\n",
    "    for func in similarity_func:\n",
    "        printlog('计算' + feature + '与query_prediction_keys_' + func.__name__  + '相似度的list', is_print_output)\n",
    "        all_data[feature + '_query_prediction_keys_' + func.__name__ +  '_list'] = all_data.apply(lambda row: [func(query, row[feature]) for query in row['query_prediction_keys_fix']], axis = 1)\n",
    "        drop_feature.append(feature + '_query_prediction_keys_' + func.__name__ + '_list')\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 计算prefix/title与query_prediction_keys相似度的list与query_prediction_values list的乘积list\n",
    "list_with_query_prediction_keys_similarity_multiple = ['prefix_fix', 'title_fix']\n",
    "multiple_similarity_func = [Levenshtein.ratio, Levenshtein.distance, lcsubstr_lens, lcseque_lens]\n",
    "for feature in list_with_query_prediction_keys_similarity_multiple:\n",
    "    for multiple_func in multiple_similarity_func:\n",
    "        printlog('计算' + feature + '与query_prediction_values_' + multiple_func.__name__  + '相似度的list的乘积list', is_print_output)\n",
    "        all_data[feature +  '_query_prediction_values_mutiple_' + multiple_func.__name__ + '_list'] = all_data.apply(lambda row: list(map(lambda x, y: x * y, row[feature + '_query_prediction_keys_' + multiple_func.__name__ +  '_list'], row['query_prediction_values'])), axis = 1)\n",
    "        drop_feature.append(feature +  '_query_prediction_values_mutiple_' + multiple_func.__name__ + '_list')\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 所有list相关统计的特征\n",
    "# 找出所有list的特征\n",
    "list_feature = list(filter(lambda x: x.find('list') != -1, drop_feature)) + ['query_prediction_values']\n",
    "for feature in list_feature:\n",
    "    for statistics in statistics_func:\n",
    "        printlog('计算' + feature + '的' + statistics.__name__, is_print_output)\n",
    "        all_data[feature + '_' + statistics.__name__] = all_data[feature].apply(lambda x: statistics(x) if x else np.nan)\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 计算prefix/title/max_query_prediction_keys间的相似度\n",
    "list_single_feature = ['prefix_fix', 'title_fix', 'query_fix']\n",
    "\n",
    "for times in range(len(list_single_feature)):\n",
    "    first_feature = list_single_feature.pop(0)\n",
    "    for second_feature in list_single_feature:\n",
    "        for func in similarity_func:\n",
    "            printlog('计算' + first_feature + '与' + second_feature + '的' + func.__name__ + '相似度', is_print_output)\n",
    "            all_data[func.__name__ + '_similarity_' + first_feature + '_with_' + second_feature] = all_data.apply(lambda row: func(row[first_feature], row[second_feature]), axis = 1)\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 拼接回原数据\n",
    "all_data = all_data.drop('query_prediction', axis = 1)\n",
    "not_zip_all_data = pd.merge(not_zip_all_data, all_data, how = 'left', on = ['prefix', 'title', 'tag', 'diction_label'])\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算某特征单次点击\n",
    "for feature in list_click_feature:\n",
    "    printlog('计算' + feature + '点击次数', is_print_output)\n",
    "    not_zip_all_data[feature + '_click'] = not_zip_all_data.groupby(feature)[feature].transform('count')\n",
    "# 部分二元交叉点击\n",
    "not_zip_all_data['prefix_title_click'] = not_zip_all_data.groupby(['prefix', 'title']).prefix.transform('count')\n",
    "not_zip_all_data['prefix_tag_click'] = not_zip_all_data.groupby(['prefix', 'tag']).prefix.transform('count')\n",
    "not_zip_all_data['title_tag_click'] = not_zip_all_data.groupby(['title', 'tag']).title.transform('count')\n",
    "not_zip_all_data['title_max_query_prediction_keys_click'] = not_zip_all_data.groupby(['title', 'max_query_prediction_keys']).title.transform('count')\n",
    "not_zip_all_data['tag_max_query_prediction_keys_click'] = not_zip_all_data.groupby(['tag', 'max_query_prediction_keys']).tag.transform('count')\n",
    "# 部分三元交叉点击\n",
    "not_zip_all_data['prefix_title_tag_click'] = not_zip_all_data.groupby(['prefix', 'title', 'tag']).prefix.transform('count')\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# 转换tag\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "not_zip_all_data['tag'] = encoder.fit_transform(not_zip_all_data.tag)\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "not_zip_all_data['prefix'] = encoder.fit_transform(not_zip_all_data.prefix)\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "not_zip_all_data['title'] = encoder.fit_transform(not_zip_all_data.title)\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "not_zip_all_data.drop(drop_feature, axis = 1).to_csv('./data/base_0610.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_elapsed = time.time() - all_start_time\n",
    "print('final complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 打印出来时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
